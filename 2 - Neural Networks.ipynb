{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks <a class=\"tocSkip\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Given is the following single neuron perceptron. In this one-layer perceptron model, the neuron calculates a\n",
    "weighted sum of inputs. Then, it applies a threshold to the result: if the sum is larger than zero, the output is 1.\n",
    "Otherwise, the output is zero.** \n",
    "\n",
    "Consider the following examples, where Z is the desired output (indeed, this is the OR function).  \n",
    "\n",
    "**In this question, you will apply the Perceptron update algorithm to automatically learn the network’s weights, so\n",
    "that it classifies correctly all the training examples. The algorithm is simple:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Iterate through the training examples, one by one (if the last example was used, and the algorithm hasn’t converged\n",
    "yet, start again from the first example, and so forth)**  \n",
    "\n",
    "For every example i:  \n",
    "\n",
    "* Calculate the net’s output Yi.  \n",
    "* Multiply the error (Zi − Yi) by the learning rate η. Add this correction to any weight for which the input in the example was non-zero.  \n",
    "That is, if for the current example i X1 = 1, then update W1 → W1 + η(Zi − Yi), etc.  \n",
    "* If the network outputs the correct result for all of the training set examples, terminate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apply the algorithm for the given training examples. Use learning rate η = 0.2. Assign the weights the initial\n",
    "values W1 = 0.1, W2 = 0.3**  \n",
    "**Give your results as specified in Table 1.**  \n",
    "**You should expect to getting the final weights within only a few passes over the training examples.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first training example (i=0) gives us a net input of $-0.5 + 0.1*0 + 0.3*0 = -0.5 $ which gets passed through the hardlim activation function resulting in a net output of 0.  \n",
    "Therefore,our error is $Z-Y = 0$ so the weights remain the same.  \n",
    "\n",
    "The second example however, gives us a positive error of 1,so the new weights are:  \n",
    "$W_1 = 0.1$ (since the corresponding input X1 is zero)  \n",
    "$W_2 = W_2 + η*(Z_1-Y_1) = 0.3 + 0.2*(1) = 0.5$  \n",
    "\n",
    "Similarly,we pass the all training examples until all of them are classified correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| X1 | X2 | W1 | W2 | Z | Y | Error | W1 | W2 |\n",
    "|----|----|----|----|---|---|-------|----|----|\n",
    "|0| 0| 0.1| 0.3| 0 |(-0.5) 0| 0| 0.1| 0.3|\n",
    "|0| 1| 0.1| 0.3 |1 |(-0.2) 0| 1| 0.1| 0.5|\n",
    "|1| 0| 0.1| 0.5 |1 |(-0.4) 0| 1| 0.3| 0.5|\n",
    "|1| 1| 0.3| 0.5 |1 |(0.3) 1 |0 |0.3 |0.5|\n",
    "|0| 0| 0.3| 0.5 |0 |(-0.5) 0| 0| 0.3| 0.5|\n",
    "|0| 1| 0.3| 0.5 |1 |(0)  0  | 1| 0.3| 0.7|\n",
    "|1| 0| 0.3| 0.7 |1 |(-0.2) 0| 1| 0.5| 0.7|\n",
    "|1| 1| 0.5| 0.7 |1 |(0.7) 1 |0 |0.5 |0.7|\n",
    "|0| 0| 0.5| 0.7 |0 |(-0.5) 0| 0| 0.5| 0.7|\n",
    "|0| 1| 0.5| 0.7 |1 |(0.2) 1 |0 |0.5 |0.7|\n",
    "|1| 0| 0.5| 0.7 |1 |(0) 0   |1 |0.7 |0.7|\n",
    "|1| 1| 0.7| 0.7 |1 |(0.9) 1 |0 |0.7 |0.7|\n",
    "|0| 0| 0.7| 0.7 |0 |(-0.5) 0| 0| 0.7| 0.7|\n",
    "|0| 1| 0.7| 0.7 |1 |(0.2) 1 |0 |0.7 |0.7|\n",
    "|1| 0| 0.7| 0.7 |0 |(0.2) 0 |0 |0.7 |0.7|\n",
    "|1| 1| 0.7| 0.7 |1 |(0.9) 1 |0 |0.7 |0.7|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since for the last epoch (pass through the entire dataset) ,all examples were classified correctly, we terminate the learning process.The final weights are 0.7 and 0.7 ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient update rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The perceptron training algorithm is in fact a simple gradient descent update. In this question, you will derive\n",
    "this algorithm.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The approach for training a perceptron here is to minimize a squared error function.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Give the definition of a squared error function, E, in terms of W1, W2, Xi1 ,Xi2 and Zi.  \n",
    "* Each weight should now be updated by taking a small step in the opposite direction of its gradient (so as to\n",
    "minimize the error):  \n",
    "\n",
    "W' = W − η∇E(W)  \n",
    "\n",
    "**Show how this translates into the algorithm that you applied in the previous question.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \n",
    "Squared\\ error = \\frac{1}{2}\\sum_i E_i ^2   \n",
    "= \\frac{1}{2}\\sum_i(Z_i - (-0.5 + W_1 X_{i1} + W_2 X_{i2}))^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the gradient of the cost function with respect to the parameters W1,W2  \n",
    "\n",
    "$$\n",
    "\\frac{dE}{dW_1} = ( (Z_i − (−0.5 + W_1 X_{i1} + W_2 X_{i2}))(−X_{i1}) = −E_i X_{i1})\n",
    "$$  \n",
    "\n",
    "$$\n",
    "\\frac{dE}{dW_2} = ( (Z_i − (−0.5 + W_1 X_{i1} + W_2 X_{i2}))(−X_{i2}) = −E_i X_{i2})\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient descent update rule for W_1 and W_2 becomes:  \n",
    "\n",
    "$$\n",
    "W_1 = W_1 + η E_i X_{i1} = W_1 + η (Z_i -Y_i) X_{i1}\n",
    "$$  \n",
    "$$\n",
    "W_2 = W_2 + η E_i X_{i2} = W_2 + η (Z_i -Y_i) X_{i2}\n",
    "$$  \n",
    "\n",
    "Which is the same as the perceptron update pule if we remember that this correction takes place for any weight for which the\n",
    "input in the example was non-zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noisy examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In practice, the training example may be noisy. Suppose that there are contradicting examples in the training\n",
    "set: for example, an additional example, where X1 = 1, X2 = 1, Z = 0. How do you think this will affect the\n",
    "algorithm’s behavior? (you are welcome to go ahead and try).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such contradicting examples make it so that the examples are not linearly seperable and since the single layer perceptron is only capable of seperating linearly seperable cases,the algorithm will not converge but run indefinitelly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
